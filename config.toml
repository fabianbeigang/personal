baseURL = "https://www.beigang.org/"
languageCode = "en-us"
title = "Fabian Beigang"
theme = "avicenna"

[params]
  subtitle= "Data Scientist and Philosopher"
  cv_name= "https://drive.google.com/file/d/1olDfPaigSfs8Q-4Zx0SJn-IidGQO2tnr/view?usp=sharing"


[[params.affilation]]
  name = "London School of Economics and Political Science"
  position = "PhD Student"
  contact = "f.beigang@lse.ac.uk"

[[params.social]]
  name = "LinkedIn"
  icon = "linkedin"
  url = "https://www.linkedin.com/in/beigang/"
  
[[params.social]]
  name = "GitHub"
  icon = "github"
  url = "https://github.com/fabianbeigang"


[[params.introduction.paragraph]]
  text="""I am a Data Scientist at the Northumbria Healthcare NHS Foundation Trust. Previously, I was a PhD student at the London School of Economics and Political Science, working
  on bias and fairness in machine learning models.  """
  
[[params.publications]]
  	[[params.publications.paper]]
		name = "On the Advantages of Distinguishing Between Predictive and Allocative Fairness in Algorithmic Decision-Making"
		dest  = "(2022), <i>Minds and Machines<\i>"
		link = "https://link.springer.com/article/10.1007/s11023-022-09615-9"

[[params.projects]]
	[[params.projects.project]]
		name = "Counterfactual Fairness, Equalized Odds, and Calibration: Yet Another Impossibility Theorem"
		description  = "When predictive models are used in decision-making processes, these models should satisfy certain mathematical fairness constraints which ensure that predictions are not discriminatory. Counterfactual fairness, equalized odds, and groupwise calibration are three of the most widely discussed such fairness constraints. In this paper we make two contributions. First, we show that for a certain class of prediction tasks, whenever a predictive model satisfies counterfactual fairness, it necessarily violates both, equalized odds and groupwise calibration. We characterize this class as prediction tasks in contexts in which the sensitive attribute has a (possibly mediated) effect on the variable that is to be predicted. We discuss different ways to avoid this conclusion by relaxing one or more of the premises of the proof. Secondly, we propose a new fairness constraint called causal relevance fairness, which is a relaxation of counterfactual fairness that retains its intuitive and philosophical appeal while being compatible with equalized odds in all possible prediction task contexts."
		project_page = "https://drive.google.com/file/d/1Z-crA8qF4g16n0y20_ezju6AlORFLeCq/view?usp=sharing"
		
